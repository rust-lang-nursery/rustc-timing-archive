commit 82d8833a456a408fe8b761a3b5e88475b65066c8
Merge: 7b3eeea 382d3b0
Author: bors <bors@rust-lang.org>
Date:   Mon Nov 21 17:59:10 2016 -0600

    Auto merge of #37642 - nnethercote:no-HirVec-of-P, r=michaelwoerister
    
    Change HirVec<P<T>> to HirVec<T> in hir:: Expr.
    
    This PR changes data structures like this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ P | P | P | P | P | P | P | P ]
                        |
                        v
                        [ ExprTup | 2 | P ]
                                        |
                                        v
                                        [ P | P ]
                                          |
                                          v
                                          [ Expr ]
    ```
    to this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ [ ExprTup | 2 | P ] | ... ]
                                        |
                                        v
                                        [ Expr | Expr ]
    ```
    I thought this would be a win for #36799, and on a cut-down version of that workload this reduces the peak heap size (as measured by Massif) from 885 MiB to 875 MiB. However, the peak RSS as measured by `-Ztime-passes` and by `/usr/bin/time` increases by about 30 MiB.
    
    I'm not sure why. Just look at the picture above -- the second data structure clearly takes up less space than the first. My best idea relates to unused elements in the slices. `HirVec<Expr>` is a typedef for `P<[Expr]>`. If there were any unused excess elements then I could see that memory usage would increase, because those excess elements are larger in `HirVec<Expr>` than in `HirVec<P<Expr>>`. But AIUI there are no such excess elements, and Massif's measurements corroborate that.
    
    However, the two main creation points for these data structures are these lines from `lower_expr`:
    ```rust
            ExprKind::Vec(ref exprs) => {
                hir::ExprArray(exprs.iter().map(|x| self.lower_expr(x)).collect())
            }
            ExprKind::Tup(ref elts) => {
                hir::ExprTup(elts.iter().map(|x| self.lower_expr(x)).collect())
            }
    ```
    I suspect what is happening is that temporary excess elements are created within the `collect` calls. The workload from #36799 has many 2-tuples and 3-tuples and when `Vec` gets doubled it goes from a capacity of 1 to 4, which would lead to excess elements. Though, having said that, `Vec::with_capacity` doesn't create excess AFAICT. So I'm not sure. What goes on inside `collect` is complex.
    
    Anyway, in its current form this PR is a memory consumption regression and so not worth landing but I figured I'd post it in case anyone has additional insight.
rustc: ./piston-image-0.10.3
cargo rustc  -- -Ztime-passes -Zinput-stats
   Compiling color_quant v1.0.0
   Compiling inflate v0.1.1
   Compiling rustc-serialize v0.3.19
   Compiling byteorder v0.5.3
   Compiling libc v0.2.16
   Compiling scoped_threadpool v0.1.7
   Compiling num-traits v0.1.35
   Compiling glob v0.2.11
   Compiling bitflags v0.7.0
   Compiling lzw v0.10.0
   Compiling gcc v0.3.35
   Compiling num_cpus v0.2.13
   Compiling rand v0.3.14
   Compiling gif v0.9.0
   Compiling num-integer v0.1.32
   Compiling num-iter v0.1.32
   Compiling num v0.1.35
   Compiling enum_primitive v0.1.0
   Compiling miniz-sys v0.1.7
   Compiling deque v0.3.1
   Compiling rayon v0.4.2
   Compiling flate2 v0.2.14
   Compiling jpeg-decoder v0.1.6
   Compiling num-bigint v0.1.35
   Compiling png v0.5.2
   Compiling num-rational v0.1.35
   Compiling image v0.10.3 (file:///root/benchmarks/piston-image-0.10.3)
time: 0.037; rss: 54MB	parsing
Lines of code:             12000
Pre-expansion node count:  90152
time: 0.000; rss: 54MB	recursion limit
time: 0.000; rss: 54MB	crate injection
time: 0.000; rss: 54MB	plugin loading
time: 0.000; rss: 54MB	plugin registration
time: 0.066; rss: 95MB	expansion
time: 0.000; rss: 95MB	maybe building test harness
time: 0.001; rss: 95MB	maybe creating a macro crate
Post-expansion node count: 148881
time: 0.000; rss: 95MB	checking for inline asm in case the target doesn't support it
time: 0.003; rss: 95MB	complete gated feature checking
time: 0.006; rss: 95MB	early lint checks
time: 0.001; rss: 95MB	AST validation
time: 0.018; rss: 98MB	name resolution
time: 0.012; rss: 106MB	lowering ast -> hir
time: 0.002; rss: 110MB	indexing hir
time: 0.002; rss: 110MB	attribute checking
time: 0.001; rss: 100MB	language item collection
time: 0.002; rss: 100MB	lifetime resolution
time: 0.000; rss: 100MB	looking for entry point
time: 0.000; rss: 100MB	looking for plugin registrar
time: 0.009; rss: 105MB	region resolution
time: 0.001; rss: 105MB	loop checking
time: 0.001; rss: 105MB	static item recursion checking
time: 0.050; rss: 105MB	compute_incremental_hashes_map
time: 0.000; rss: 105MB	load_dep_graph
time: 0.016; rss: 107MB	type collecting
time: 0.000; rss: 107MB	variance inference
time: 0.000; rss: 107MB	impl wf inference
time: 0.014; rss: 109MB	coherence checking
time: 0.067; rss: 110MB	wf checking
time: 0.133; rss: 112MB	item-types checking
time: 0.774; rss: 124MB	item-bodies checking
time: 0.000; rss: 124MB	drop-impl checking
time: 0.048; rss: 127MB	const checking
time: 0.008; rss: 127MB	privacy checking
time: 0.001; rss: 127MB	stability index
time: 0.006; rss: 127MB	intrinsic checking
time: 0.002; rss: 127MB	effect checking
time: 0.013; rss: 127MB	match checking
time: 0.009; rss: 127MB	liveness checking
time: 0.039; rss: 127MB	rvalue checking
time: 0.087; rss: 170MB	MIR dump
  time: 0.011; rss: 170MB	SimplifyCfg
  time: 0.019; rss: 170MB	QualifyAndPromoteConstants
  time: 0.022; rss: 170MB	TypeckMir
  time: 0.001; rss: 170MB	SimplifyBranches
  time: 0.004; rss: 170MB	SimplifyCfg
time: 0.058; rss: 170MB	MIR cleanup and validation
time: 0.106; rss: 170MB	borrow checking
time: 0.003; rss: 170MB	reachability checking
time: 0.007; rss: 170MB	death checking
time: 0.007; rss: 170MB	stability checking
time: 0.000; rss: 170MB	unused lib feature checking
time: 0.061; rss: 170MB	lint checking
time: 0.000; rss: 170MB	resolving dependency formats
  time: 0.000; rss: 170MB	NoLandingPads
  time: 0.005; rss: 170MB	SimplifyCfg
  time: 0.010; rss: 170MB	EraseRegions
  time: 0.002; rss: 170MB	AddCallGuards
  time: 0.041; rss: 173MB	ElaborateDrops
  time: 0.000; rss: 173MB	NoLandingPads
  time: 0.009; rss: 173MB	SimplifyCfg
  time: 0.006; rss: 173MB	InstCombine
  time: 0.002; rss: 173MB	Deaggregator
  time: 0.000; rss: 173MB	CopyPropagation
  time: 0.007; rss: 173MB	SimplifyLocals
  time: 0.002; rss: 173MB	AddCallGuards
  time: 0.000; rss: 173MB	PreTrans
time: 0.085; rss: 173MB	MIR optimisations
  time: 0.016; rss: 175MB	write metadata
  time: 0.414; rss: 189MB	translation item collection
  time: 0.020; rss: 193MB	codegen unit partitioning
  time: 0.018; rss: 315MB	internalize symbols
time: 2.290; rss: 315MB	translation
time: 0.000; rss: 315MB	assert dep graph
time: 0.000; rss: 315MB	serialize dep graph
  time: 0.202; rss: 231MB	llvm function passes [0]
  time: 0.081; rss: 233MB	llvm module passes [0]
  time: 4.158; rss: 232MB	codegen passes [0]
  time: 0.000; rss: 232MB	codegen passes [0]
time: 4.742; rss: 232MB	LLVM passes
time: 0.000; rss: 232MB	serialize work products
time: 0.126; rss: 104MB	linking
done
