commit 82d8833a456a408fe8b761a3b5e88475b65066c8
Merge: 7b3eeea 382d3b0
Author: bors <bors@rust-lang.org>
Date:   Mon Nov 21 17:59:10 2016 -0600

    Auto merge of #37642 - nnethercote:no-HirVec-of-P, r=michaelwoerister
    
    Change HirVec<P<T>> to HirVec<T> in hir:: Expr.
    
    This PR changes data structures like this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ P | P | P | P | P | P | P | P ]
                        |
                        v
                        [ ExprTup | 2 | P ]
                                        |
                                        v
                                        [ P | P ]
                                          |
                                          v
                                          [ Expr ]
    ```
    to this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ [ ExprTup | 2 | P ] | ... ]
                                        |
                                        v
                                        [ Expr | Expr ]
    ```
    I thought this would be a win for #36799, and on a cut-down version of that workload this reduces the peak heap size (as measured by Massif) from 885 MiB to 875 MiB. However, the peak RSS as measured by `-Ztime-passes` and by `/usr/bin/time` increases by about 30 MiB.
    
    I'm not sure why. Just look at the picture above -- the second data structure clearly takes up less space than the first. My best idea relates to unused elements in the slices. `HirVec<Expr>` is a typedef for `P<[Expr]>`. If there were any unused excess elements then I could see that memory usage would increase, because those excess elements are larger in `HirVec<Expr>` than in `HirVec<P<Expr>>`. But AIUI there are no such excess elements, and Massif's measurements corroborate that.
    
    However, the two main creation points for these data structures are these lines from `lower_expr`:
    ```rust
            ExprKind::Vec(ref exprs) => {
                hir::ExprArray(exprs.iter().map(|x| self.lower_expr(x)).collect())
            }
            ExprKind::Tup(ref elts) => {
                hir::ExprTup(elts.iter().map(|x| self.lower_expr(x)).collect())
            }
    ```
    I suspect what is happening is that temporary excess elements are created within the `collect` calls. The workload from #36799 has many 2-tuples and 3-tuples and when `Vec` gets doubled it goes from a capacity of 1 to 4, which would lead to excess elements. Though, having said that, `Vec::with_capacity` doesn't create excess AFAICT. So I'm not sure. What goes on inside `collect` is complex.
    
    Anyway, in its current form this PR is a memory consumption regression and so not worth landing but I figured I'd post it in case anyone has additional insight.
rustc: ./html5ever-2016-08-25
cargo rustc  -- -Ztime-passes -Zinput-stats
   Compiling html5ever v0.5.4 (file:///root/benchmarks/html5ever-2016-08-25)
time: 0.023; rss: 49MB	parsing
Lines of code:             8210
Pre-expansion node count:  52140
time: 0.000; rss: 49MB	recursion limit
time: 0.000; rss: 49MB	crate injection
time: 0.000; rss: 49MB	plugin loading
time: 0.000; rss: 49MB	plugin registration
time: 0.643; rss: 102MB	expansion
time: 0.000; rss: 102MB	maybe building test harness
time: 0.002; rss: 102MB	maybe creating a macro crate
Post-expansion node count: 163412
time: 0.000; rss: 102MB	checking for inline asm in case the target doesn't support it
time: 0.002; rss: 102MB	complete gated feature checking
time: 0.008; rss: 102MB	early lint checks
time: 0.002; rss: 102MB	AST validation
time: 0.015; rss: 105MB	name resolution
time: 0.011; rss: 113MB	lowering ast -> hir
time: 0.002; rss: 116MB	indexing hir
time: 0.002; rss: 116MB	attribute checking
time: 0.001; rss: 97MB	language item collection
time: 0.002; rss: 97MB	lifetime resolution
time: 0.000; rss: 97MB	looking for entry point
time: 0.000; rss: 97MB	looking for plugin registrar
time: 0.011; rss: 105MB	region resolution
time: 0.001; rss: 105MB	loop checking
time: 0.001; rss: 105MB	static item recursion checking
time: 0.020; rss: 106MB	compute_incremental_hashes_map
time: 0.000; rss: 106MB	load_dep_graph
time: 0.009; rss: 108MB	type collecting
time: 0.000; rss: 108MB	variance inference
time: 0.000; rss: 108MB	impl wf inference
time: 0.011; rss: 109MB	coherence checking
time: 0.020; rss: 110MB	wf checking
time: 0.259; rss: 121MB	item-types checking
time: 0.456; rss: 130MB	item-bodies checking
time: 0.000; rss: 130MB	drop-impl checking
time: 0.056; rss: 137MB	const checking
time: 0.005; rss: 137MB	privacy checking
time: 0.001; rss: 137MB	stability index
time: 0.002; rss: 137MB	intrinsic checking
time: 0.002; rss: 137MB	effect checking
time: 0.014; rss: 137MB	match checking
time: 0.011; rss: 131MB	liveness checking
time: 0.021; rss: 131MB	rvalue checking
time: 0.100; rss: 172MB	MIR dump
  time: 0.008; rss: 172MB	SimplifyCfg
  time: 0.013; rss: 175MB	QualifyAndPromoteConstants
  time: 0.022; rss: 175MB	TypeckMir
  time: 0.000; rss: 175MB	SimplifyBranches
  time: 0.004; rss: 175MB	SimplifyCfg
time: 0.048; rss: 175MB	MIR cleanup and validation
time: 0.079; rss: 179MB	borrow checking
time: 0.002; rss: 179MB	reachability checking
time: 0.005; rss: 179MB	death checking
time: 0.006; rss: 179MB	stability checking
time: 0.000; rss: 179MB	unused lib feature checking
time: 0.055; rss: 179MB	lint checking
time: 0.000; rss: 179MB	resolving dependency formats
  time: 0.000; rss: 179MB	NoLandingPads
  time: 0.003; rss: 179MB	SimplifyCfg
  time: 0.009; rss: 180MB	EraseRegions
  time: 0.001; rss: 180MB	AddCallGuards
  time: 0.072; rss: 182MB	ElaborateDrops
  time: 0.000; rss: 182MB	NoLandingPads
  time: 0.006; rss: 182MB	SimplifyCfg
  time: 0.007; rss: 180MB	InstCombine
  time: 0.001; rss: 180MB	Deaggregator
  time: 0.000; rss: 180MB	CopyPropagation
  time: 0.007; rss: 178MB	SimplifyLocals
  time: 0.001; rss: 178MB	AddCallGuards
  time: 0.000; rss: 178MB	PreTrans
time: 0.108; rss: 178MB	MIR optimisations
  time: 0.011; rss: 179MB	write metadata
  time: 0.038; rss: 180MB	translation item collection
  time: 0.004; rss: 180MB	codegen unit partitioning
  time: 0.005; rss: 194MB	internalize symbols
time: 0.266; rss: 194MB	translation
time: 0.000; rss: 194MB	assert dep graph
time: 0.000; rss: 194MB	serialize dep graph
  time: 0.020; rss: 108MB	llvm function passes [0]
  time: 0.012; rss: 110MB	llvm module passes [0]
  time: 0.477; rss: 113MB	codegen passes [0]
  time: 0.000; rss: 113MB	codegen passes [0]
time: 0.549; rss: 113MB	LLVM passes
time: 0.000; rss: 113MB	serialize work products
time: 0.025; rss: 95MB	linking
done
