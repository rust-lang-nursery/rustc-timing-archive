commit 82d8833a456a408fe8b761a3b5e88475b65066c8
Merge: 7b3eeea 382d3b0
Author: bors <bors@rust-lang.org>
Date:   Mon Nov 21 17:59:10 2016 -0600

    Auto merge of #37642 - nnethercote:no-HirVec-of-P, r=michaelwoerister
    
    Change HirVec<P<T>> to HirVec<T> in hir:: Expr.
    
    This PR changes data structures like this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ P | P | P | P | P | P | P | P ]
                        |
                        v
                        [ ExprTup | 2 | P ]
                                        |
                                        v
                                        [ P | P ]
                                          |
                                          v
                                          [ Expr ]
    ```
    to this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ [ ExprTup | 2 | P ] | ... ]
                                        |
                                        v
                                        [ Expr | Expr ]
    ```
    I thought this would be a win for #36799, and on a cut-down version of that workload this reduces the peak heap size (as measured by Massif) from 885 MiB to 875 MiB. However, the peak RSS as measured by `-Ztime-passes` and by `/usr/bin/time` increases by about 30 MiB.
    
    I'm not sure why. Just look at the picture above -- the second data structure clearly takes up less space than the first. My best idea relates to unused elements in the slices. `HirVec<Expr>` is a typedef for `P<[Expr]>`. If there were any unused excess elements then I could see that memory usage would increase, because those excess elements are larger in `HirVec<Expr>` than in `HirVec<P<Expr>>`. But AIUI there are no such excess elements, and Massif's measurements corroborate that.
    
    However, the two main creation points for these data structures are these lines from `lower_expr`:
    ```rust
            ExprKind::Vec(ref exprs) => {
                hir::ExprArray(exprs.iter().map(|x| self.lower_expr(x)).collect())
            }
            ExprKind::Tup(ref elts) => {
                hir::ExprTup(elts.iter().map(|x| self.lower_expr(x)).collect())
            }
    ```
    I suspect what is happening is that temporary excess elements are created within the `collect` calls. The workload from #36799 has many 2-tuples and 3-tuples and when `Vec` gets doubled it goes from a capacity of 1 to 4, which would lead to excess elements. Though, having said that, `Vec::with_capacity` doesn't create excess AFAICT. So I'm not sure. What goes on inside `collect` is complex.
    
    Anyway, in its current form this PR is a memory consumption regression and so not worth landing but I figured I'd post it in case anyone has additional insight.
rustc: ./rust-encoding-0.3.0
cargo rustc  -- -Ztime-passes -Zinput-stats
   Compiling encoding_index_tests v0.1.5 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-types v0.2.0 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-index-korean v1.20141219.6 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-index-singlebyte v1.20160120.0 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-index-simpchinese v1.20160120.0 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-index-japanese v1.20141219.6 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding-index-tradchinese v1.20141219.6 (file:///root/benchmarks/rust-encoding-0.3.0)
   Compiling encoding v0.3.0-dev (file:///root/benchmarks/rust-encoding-0.3.0)
time: 0.016; rss: 45MB	parsing
Lines of code:             5757
Pre-expansion node count:  26523
time: 0.000; rss: 45MB	recursion limit
time: 0.000; rss: 45MB	crate injection
time: 0.000; rss: 45MB	plugin loading
time: 0.000; rss: 45MB	plugin registration
time: 0.030; rss: 75MB	expansion
time: 0.000; rss: 75MB	maybe building test harness
time: 0.000; rss: 75MB	maybe creating a macro crate
Post-expansion node count: 37888
time: 0.000; rss: 75MB	checking for inline asm in case the target doesn't support it
time: 0.000; rss: 75MB	complete gated feature checking
time: 0.001; rss: 75MB	early lint checks
time: 0.000; rss: 75MB	AST validation
time: 0.004; rss: 75MB	name resolution
time: 0.003; rss: 77MB	lowering ast -> hir
time: 0.000; rss: 77MB	indexing hir
time: 0.000; rss: 77MB	attribute checking
time: 0.000; rss: 76MB	language item collection
time: 0.000; rss: 76MB	lifetime resolution
time: 0.000; rss: 76MB	looking for entry point
time: 0.000; rss: 76MB	looking for plugin registrar
time: 0.002; rss: 78MB	region resolution
time: 0.000; rss: 78MB	loop checking
time: 0.000; rss: 78MB	static item recursion checking
time: 0.013; rss: 78MB	compute_incremental_hashes_map
time: 0.000; rss: 78MB	load_dep_graph
time: 0.007; rss: 79MB	type collecting
time: 0.000; rss: 79MB	variance inference
time: 0.000; rss: 80MB	impl wf inference
time: 0.007; rss: 80MB	coherence checking
time: 0.010; rss: 81MB	wf checking
time: 0.009; rss: 81MB	item-types checking
time: 0.112; rss: 86MB	item-bodies checking
time: 0.000; rss: 86MB	drop-impl checking
time: 0.007; rss: 86MB	const checking
time: 0.001; rss: 86MB	privacy checking
time: 0.000; rss: 86MB	stability index
time: 0.001; rss: 86MB	intrinsic checking
time: 0.000; rss: 86MB	effect checking
time: 0.004; rss: 86MB	match checking
time: 0.001; rss: 86MB	liveness checking
time: 0.004; rss: 86MB	rvalue checking
time: 0.016; rss: 93MB	MIR dump
  time: 0.002; rss: 93MB	SimplifyCfg
  time: 0.003; rss: 93MB	QualifyAndPromoteConstants
  time: 0.004; rss: 93MB	TypeckMir
  time: 0.000; rss: 93MB	SimplifyBranches
  time: 0.001; rss: 93MB	SimplifyCfg
time: 0.011; rss: 93MB	MIR cleanup and validation
time: 0.017; rss: 93MB	borrow checking
time: 0.000; rss: 93MB	reachability checking
time: 0.001; rss: 93MB	death checking
time: 0.001; rss: 93MB	stability checking
time: 0.000; rss: 93MB	unused lib feature checking
time: 0.013; rss: 93MB	lint checking
time: 0.000; rss: 93MB	resolving dependency formats
  time: 0.000; rss: 93MB	NoLandingPads
  time: 0.001; rss: 93MB	SimplifyCfg
  time: 0.002; rss: 93MB	EraseRegions
  time: 0.000; rss: 93MB	AddCallGuards
  time: 0.022; rss: 95MB	ElaborateDrops
  time: 0.000; rss: 95MB	NoLandingPads
  time: 0.001; rss: 95MB	SimplifyCfg
  time: 0.001; rss: 95MB	InstCombine
  time: 0.001; rss: 95MB	Deaggregator
  time: 0.000; rss: 95MB	CopyPropagation
  time: 0.001; rss: 95MB	SimplifyLocals
  time: 0.000; rss: 95MB	AddCallGuards
  time: 0.000; rss: 95MB	PreTrans
time: 0.031; rss: 95MB	MIR optimisations
  time: 0.004; rss: 95MB	write metadata
  time: 0.134; rss: 179MB	translation item collection
  time: 0.002; rss: 179MB	codegen unit partitioning
  time: 0.002; rss: 205MB	internalize symbols
time: 0.382; rss: 205MB	translation
time: 0.000; rss: 205MB	assert dep graph
time: 0.000; rss: 205MB	serialize dep graph
  time: 0.024; rss: 115MB	llvm function passes [0]
  time: 0.055; rss: 119MB	llvm module passes [0]
  time: 0.621; rss: 126MB	codegen passes [0]
  time: 0.000; rss: 126MB	codegen passes [0]
time: 0.757; rss: 126MB	LLVM passes
time: 0.000; rss: 126MB	serialize work products
time: 0.038; rss: 96MB	linking
done
