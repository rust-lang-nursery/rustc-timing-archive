commit 82d8833a456a408fe8b761a3b5e88475b65066c8
Merge: 7b3eeea 382d3b0
Author: bors <bors@rust-lang.org>
Date:   Mon Nov 21 17:59:10 2016 -0600

    Auto merge of #37642 - nnethercote:no-HirVec-of-P, r=michaelwoerister
    
    Change HirVec<P<T>> to HirVec<T> in hir:: Expr.
    
    This PR changes data structures like this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ P | P | P | P | P | P | P | P ]
                        |
                        v
                        [ ExprTup | 2 | P ]
                                        |
                                        v
                                        [ P | P ]
                                          |
                                          v
                                          [ Expr ]
    ```
    to this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ [ ExprTup | 2 | P ] | ... ]
                                        |
                                        v
                                        [ Expr | Expr ]
    ```
    I thought this would be a win for #36799, and on a cut-down version of that workload this reduces the peak heap size (as measured by Massif) from 885 MiB to 875 MiB. However, the peak RSS as measured by `-Ztime-passes` and by `/usr/bin/time` increases by about 30 MiB.
    
    I'm not sure why. Just look at the picture above -- the second data structure clearly takes up less space than the first. My best idea relates to unused elements in the slices. `HirVec<Expr>` is a typedef for `P<[Expr]>`. If there were any unused excess elements then I could see that memory usage would increase, because those excess elements are larger in `HirVec<Expr>` than in `HirVec<P<Expr>>`. But AIUI there are no such excess elements, and Massif's measurements corroborate that.
    
    However, the two main creation points for these data structures are these lines from `lower_expr`:
    ```rust
            ExprKind::Vec(ref exprs) => {
                hir::ExprArray(exprs.iter().map(|x| self.lower_expr(x)).collect())
            }
            ExprKind::Tup(ref elts) => {
                hir::ExprTup(elts.iter().map(|x| self.lower_expr(x)).collect())
            }
    ```
    I suspect what is happening is that temporary excess elements are created within the `collect` calls. The workload from #36799 has many 2-tuples and 3-tuples and when `Vec` gets doubled it goes from a capacity of 1 to 4, which would lead to excess elements. Though, having said that, `Vec::with_capacity` doesn't create excess AFAICT. So I'm not sure. What goes on inside `collect` is complex.
    
    Anyway, in its current form this PR is a memory consumption regression and so not worth landing but I figured I'd post it in case anyone has additional insight.
rustc: ./issue-32278-big-array-of-strings
cargo rustc  -- -Ztime-passes -Zinput-stats
   Compiling issue-32278-big-array-of-strings v0.1.0 (file:///root/benchmarks/issue-32278-big-array-of-strings)
time: 0.101; rss: 60MB	parsing
Lines of code:             65577
Pre-expansion node count:  65552
time: 0.000; rss: 60MB	recursion limit
time: 0.000; rss: 60MB	crate injection
time: 0.000; rss: 60MB	plugin loading
time: 0.000; rss: 60MB	plugin registration
time: 0.023; rss: 85MB	expansion
time: 0.000; rss: 85MB	maybe building test harness
time: 0.001; rss: 85MB	maybe creating a macro crate
Post-expansion node count: 65565
time: 0.000; rss: 85MB	checking for inline asm in case the target doesn't support it
time: 0.000; rss: 85MB	complete gated feature checking
time: 0.004; rss: 85MB	early lint checks
time: 0.000; rss: 85MB	AST validation
time: 0.002; rss: 85MB	name resolution
time: 0.004; rss: 93MB	lowering ast -> hir
time: 0.001; rss: 97MB	indexing hir
time: 0.001; rss: 97MB	attribute checking
time: 0.000; rss: 86MB	language item collection
time: 0.000; rss: 86MB	lifetime resolution
time: 0.000; rss: 86MB	looking for entry point
time: 0.000; rss: 86MB	looking for plugin registrar
time: 0.005; rss: 92MB	region resolution
time: 0.000; rss: 92MB	loop checking
time: 0.001; rss: 92MB	static item recursion checking
time: 0.019; rss: 92MB	compute_incremental_hashes_map
time: 0.000; rss: 92MB	load_dep_graph
time: 0.000; rss: 92MB	type collecting
time: 0.000; rss: 92MB	variance inference
time: 0.000; rss: 92MB	impl wf inference
time: 0.004; rss: 94MB	coherence checking
time: 0.000; rss: 94MB	wf checking
time: 0.527; rss: 103MB	item-types checking
time: 0.000; rss: 103MB	item-bodies checking
time: 0.000; rss: 103MB	drop-impl checking
time: 0.020; rss: 107MB	const checking
time: 0.001; rss: 107MB	privacy checking
time: 0.000; rss: 107MB	stability index
time: 0.000; rss: 107MB	intrinsic checking
time: 0.000; rss: 107MB	effect checking
time: 0.000; rss: 107MB	match checking
time: 0.000; rss: 107MB	liveness checking
time: 0.000; rss: 107MB	rvalue checking
time: 0.035; rss: 115MB	MIR dump
  time: 0.000; rss: 115MB	SimplifyCfg
  time: 0.001; rss: 115MB	QualifyAndPromoteConstants
  time: 0.000; rss: 115MB	TypeckMir
  time: 0.000; rss: 115MB	SimplifyBranches
  time: 0.000; rss: 115MB	SimplifyCfg
time: 0.001; rss: 115MB	MIR cleanup and validation
time: 0.001; rss: 115MB	borrow checking
time: 0.000; rss: 115MB	reachability checking
time: 0.000; rss: 115MB	death checking
time: 0.000; rss: 115MB	stability checking
time: 0.000; rss: 115MB	unused lib feature checking
time: 0.023; rss: 115MB	lint checking
time: 0.001; rss: 115MB	resolving dependency formats
  time: 0.000; rss: 115MB	NoLandingPads
  time: 0.000; rss: 115MB	SimplifyCfg
  time: 0.001; rss: 115MB	EraseRegions
  time: 0.000; rss: 115MB	AddCallGuards
  time: 0.000; rss: 115MB	ElaborateDrops
  time: 0.000; rss: 115MB	NoLandingPads
  time: 0.000; rss: 115MB	SimplifyCfg
  time: 0.000; rss: 115MB	InstCombine
  time: 0.000; rss: 115MB	Deaggregator
  time: 0.000; rss: 115MB	CopyPropagation
  time: 0.000; rss: 115MB	SimplifyLocals
  time: 0.000; rss: 115MB	AddCallGuards
  time: 0.000; rss: 115MB	PreTrans
time: 0.001; rss: 115MB	MIR optimisations
  time: 0.000; rss: 115MB	write metadata
  time: 0.000; rss: 115MB	translation item collection
  time: 0.000; rss: 115MB	codegen unit partitioning
  time: 0.001; rss: 126MB	internalize symbols
time: 0.057; rss: 126MB	translation
time: 0.000; rss: 126MB	assert dep graph
time: 0.000; rss: 126MB	serialize dep graph
  time: 0.008; rss: 91MB	llvm function passes [0]
  time: 0.000; rss: 91MB	llvm module passes [0]
  time: 0.190; rss: 91MB	codegen passes [0]
  time: 0.000; rss: 91MB	codegen passes [0]
time: 0.199; rss: 91MB	LLVM passes
time: 0.000; rss: 91MB	serialize work products
  time: 0.152; rss: 81MB	running linker
time: 0.153; rss: 81MB	linking
done
