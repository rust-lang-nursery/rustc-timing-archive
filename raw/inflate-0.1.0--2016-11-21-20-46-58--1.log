commit 82d8833a456a408fe8b761a3b5e88475b65066c8
Merge: 7b3eeea 382d3b0
Author: bors <bors@rust-lang.org>
Date:   Mon Nov 21 17:59:10 2016 -0600

    Auto merge of #37642 - nnethercote:no-HirVec-of-P, r=michaelwoerister
    
    Change HirVec<P<T>> to HirVec<T> in hir:: Expr.
    
    This PR changes data structures like this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ P | P | P | P | P | P | P | P ]
                        |
                        v
                        [ ExprTup | 2 | P ]
                                        |
                                        v
                                        [ P | P ]
                                          |
                                          v
                                          [ Expr ]
    ```
    to this:
    ```
    [ ExprArray | 8 | P ]
                      |
                      v
                      [ [ ExprTup | 2 | P ] | ... ]
                                        |
                                        v
                                        [ Expr | Expr ]
    ```
    I thought this would be a win for #36799, and on a cut-down version of that workload this reduces the peak heap size (as measured by Massif) from 885 MiB to 875 MiB. However, the peak RSS as measured by `-Ztime-passes` and by `/usr/bin/time` increases by about 30 MiB.
    
    I'm not sure why. Just look at the picture above -- the second data structure clearly takes up less space than the first. My best idea relates to unused elements in the slices. `HirVec<Expr>` is a typedef for `P<[Expr]>`. If there were any unused excess elements then I could see that memory usage would increase, because those excess elements are larger in `HirVec<Expr>` than in `HirVec<P<Expr>>`. But AIUI there are no such excess elements, and Massif's measurements corroborate that.
    
    However, the two main creation points for these data structures are these lines from `lower_expr`:
    ```rust
            ExprKind::Vec(ref exprs) => {
                hir::ExprArray(exprs.iter().map(|x| self.lower_expr(x)).collect())
            }
            ExprKind::Tup(ref elts) => {
                hir::ExprTup(elts.iter().map(|x| self.lower_expr(x)).collect())
            }
    ```
    I suspect what is happening is that temporary excess elements are created within the `collect` calls. The workload from #36799 has many 2-tuples and 3-tuples and when `Vec` gets doubled it goes from a capacity of 1 to 4, which would lead to excess elements. Though, having said that, `Vec::with_capacity` doesn't create excess AFAICT. So I'm not sure. What goes on inside `collect` is complex.
    
    Anyway, in its current form this PR is a memory consumption regression and so not worth landing but I figured I'd post it in case anyone has additional insight.
rustc: ./inflate-0.1.0
cargo rustc  -- -Ztime-passes -Zinput-stats
   Compiling inflate v0.1.0 (file:///root/benchmarks/inflate-0.1.0)
time: 0.003; rss: 43MB	parsing
Lines of code:             956
Pre-expansion node count:  4736
time: 0.000; rss: 43MB	recursion limit
time: 0.000; rss: 43MB	crate injection
time: 0.000; rss: 43MB	plugin loading
time: 0.000; rss: 43MB	plugin registration
time: 0.056; rss: 72MB	expansion
time: 0.000; rss: 72MB	maybe building test harness
time: 0.000; rss: 72MB	maybe creating a macro crate
Post-expansion node count: 55748
time: 0.000; rss: 72MB	checking for inline asm in case the target doesn't support it
time: 0.000; rss: 72MB	complete gated feature checking
time: 0.002; rss: 72MB	early lint checks
time: 0.000; rss: 72MB	AST validation
time: 0.007; rss: 74MB	name resolution
time: 0.004; rss: 76MB	lowering ast -> hir
time: 0.001; rss: 76MB	indexing hir
time: 0.001; rss: 76MB	attribute checking
time: 0.000; rss: 73MB	language item collection
time: 0.000; rss: 73MB	lifetime resolution
time: 0.000; rss: 73MB	looking for entry point
time: 0.000; rss: 73MB	looking for plugin registrar
time: 0.002; rss: 75MB	region resolution
time: 0.000; rss: 75MB	loop checking
time: 0.000; rss: 75MB	static item recursion checking
time: 0.018; rss: 75MB	compute_incremental_hashes_map
time: 0.000; rss: 75MB	load_dep_graph
time: 0.001; rss: 77MB	type collecting
time: 0.000; rss: 77MB	variance inference
time: 0.000; rss: 77MB	impl wf inference
time: 0.006; rss: 79MB	coherence checking
time: 0.001; rss: 80MB	wf checking
time: 0.001; rss: 80MB	item-types checking
time: 1.606; rss: 86MB	item-bodies checking
time: 0.000; rss: 86MB	drop-impl checking
time: 0.014; rss: 87MB	const checking
time: 0.001; rss: 87MB	privacy checking
time: 0.000; rss: 87MB	stability index
time: 0.000; rss: 87MB	intrinsic checking
time: 0.000; rss: 87MB	effect checking
time: 0.002; rss: 87MB	match checking
time: 0.065; rss: 85MB	liveness checking
time: 0.011; rss: 85MB	rvalue checking
time: 0.034; rss: 104MB	MIR dump
  time: 0.007; rss: 107MB	SimplifyCfg
  time: 0.005; rss: 107MB	QualifyAndPromoteConstants
  time: 0.007; rss: 107MB	TypeckMir
  time: 0.000; rss: 107MB	SimplifyBranches
  time: 0.002; rss: 107MB	SimplifyCfg
time: 0.021; rss: 107MB	MIR cleanup and validation
time: 0.211; rss: 107MB	borrow checking
time: 0.000; rss: 107MB	reachability checking
time: 0.003; rss: 107MB	death checking
time: 0.001; rss: 107MB	stability checking
time: 0.000; rss: 107MB	unused lib feature checking
time: 0.016; rss: 108MB	lint checking
time: 0.000; rss: 108MB	resolving dependency formats
  time: 0.000; rss: 108MB	NoLandingPads
  time: 0.002; rss: 108MB	SimplifyCfg
  time: 0.003; rss: 108MB	EraseRegions
  time: 0.001; rss: 108MB	AddCallGuards
  time: 0.222; rss: 110MB	ElaborateDrops
  time: 0.000; rss: 110MB	NoLandingPads
  time: 0.006; rss: 110MB	SimplifyCfg
  time: 0.003; rss: 110MB	InstCombine
  time: 0.000; rss: 110MB	Deaggregator
  time: 0.000; rss: 110MB	CopyPropagation
  time: 0.003; rss: 110MB	SimplifyLocals
  time: 0.001; rss: 109MB	AddCallGuards
  time: 0.000; rss: 109MB	PreTrans
time: 0.240; rss: 109MB	MIR optimisations
  time: 0.001; rss: 109MB	write metadata
  time: 0.008; rss: 110MB	translation item collection
  time: 0.001; rss: 110MB	codegen unit partitioning
  time: 0.001; rss: 123MB	internalize symbols
time: 0.143; rss: 123MB	translation
time: 0.000; rss: 123MB	assert dep graph
time: 0.000; rss: 123MB	serialize dep graph
  time: 0.026; rss: 91MB	llvm function passes [0]
  time: 0.005; rss: 91MB	llvm module passes [0]
  time: 0.655; rss: 98MB	codegen passes [0]
  time: 0.000; rss: 98MB	codegen passes [0]
time: 0.719; rss: 98MB	LLVM passes
time: 0.000; rss: 98MB	serialize work products
time: 0.019; rss: 85MB	linking
done
